{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xy_9hARVUo9L"
      },
      "source": [
        "# SC42x \n",
        "## 자연어처리 (Natural Language Processing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dNUXHiLbBdp"
      },
      "source": [
        "# Part 1 : 개념 요약\n",
        "\n",
        "> 다음의 키워드에 대해서 **한 줄**로 간단하게 요약해주세요. (세션 노트를 참고하여도 좋습니다.)<br/>\n",
        "> **Tip : 아래 문제를 먼저 수행한 후 모델 학습 등 시간이 오래 걸리는 셀이 실행되는 동안 아래 내용을 작성하면 시간을 절약할 수 있습니다.**\n",
        "\n",
        "**N421**\n",
        "- **Stopwords(불용어)** : 분석에 큰 의미가 없는 단어\n",
        "- **Stemming** : 단어에서 접사 등을 제거하고 단어의 의미를 담고 있는 단어의 핵심 부분을 남기는 작업\n",
        "- **Lemmatization** : 단어의 뿌리 단어를 찾아가는 작업\n",
        "- **Bag-of-Words** : 문서에서 문법이나 단어의 순서 등을 무시하고 단순히 단어들의 빈도만 고려하여 벡터화하는 방법\n",
        "- **TF-IDF** : 특정 문서에만 등장하는 단어에 가중치를 두는 방법\n",
        "\n",
        "**N422**\n",
        "- **Word2Vec** : 단어를 벡터로 나타내는 방법\n",
        "- **fastText** : Word2vec 기반으로 부분단어들을 임베딩하는 기법\n",
        "\n",
        "**N423**\n",
        "- **RNN** : 입력과 출력을 시퀀스 단위로 처리하는 모델\n",
        "- **LSTM** : RNN에 기울기 정보 크기를 조절하기 위한 Gate를 추가한 모델\n",
        "- **GRU** : LSTM을 간소화한 모델로 시간 측면에서 좀 더 빠름\n",
        "- **Attention** : 디코더에서 출력 단어를 예측하는 시점마다, 인코더 입력 문장 중에서 해당 시점에서 예측해야할 단어와 연관이 있는 단어를 더 집중해서 보는 기법"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g07_yjCgbBdp"
      },
      "source": [
        "# Part 2 : Fake/Real News Dataset\n",
        "\n",
        "한 주간 자연어처리 기법을 배우면서 여러분은 다양한 기술들을 접했습니다.<br/>\n",
        "어떻게 텍스트 데이터를 다뤄야 하는지, 텍스트를 벡터화 하는 법, 문서에서 토픽을 모델하는 법 등 다양한 NLP 기법을 배웠는데요.<br/>\n",
        "이번 스프린트 챌린지에선 [Fake/Real News Dataset](https://www.kaggle.com/clmentbisaillon/fake-and-real-news-dataset)을 사용하여 배운 것들을 복습해보는 시간을 갖겠습니다.\n",
        "\n",
        "**주의 : 모델의 성능을 최대한 끌어올리는 것이 아닌 모델 구동에 초점을 맞춰주세요.<br/>\n",
        "모든 문제를 완료한 후에도 \"시간이 남았다면\" 정확도를 올리는 것에 도전하시는 것을 추천드립니다.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "BCX5K0nP0ZKQ"
      },
      "outputs": [],
      "source": [
        "# 코드 실행 전 seed를 지정하겠습니다.\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C08-JiyNbdQy"
      },
      "source": [
        "## 2.0 데이터셋을 불러옵니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyndWa5hxEmk"
      },
      "source": [
        "- 위 캐글 링크에서 데이터셋을 받아 업로드 합니다.<br/>\n",
        "(직접 업로드하게 되면 시간이 꽤 걸리므로 **drive_mount** 나 **kaggle 연동**하시는 것을 추천드립니다.)\n",
        "\n",
        "- 'label' 열을 만들어 Fake = 1, True = 0 로 레이블링해줍니다.\n",
        "- 두 파일을 합쳐 하나의 데이터프레임에 저장해 준 후 데이터를 섞어줍니다."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 파일 저장\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "id": "B8P0qTC6qSTf",
        "outputId": "c3fa71fe-9aa7-4df5-e46a-a4657c3cbb96"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d691de60-6bc9-475f-aec7-33517d61c9a6\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d691de60-6bc9-475f-aec7-33517d61c9a6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving True.csv to True.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 파일 불러오기\n",
        "import pandas as pd\n",
        "\n",
        "df_fake = pd.read_csv('Fake.csv')\n",
        "df_true = pd.read_csv('True.csv')"
      ],
      "metadata": {
        "id": "_eSkSHosv10g"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_fake 정보 확인\n",
        "df_fake.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8nsbWp5w0uh",
        "outputId": "5e2ba8a3-c2c4-475d-e8e7-5da2bc7ca4d4"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 23481 entries, 0 to 23480\n",
            "Data columns (total 4 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   title    23481 non-null  object\n",
            " 1   text     23481 non-null  object\n",
            " 2   subject  23481 non-null  object\n",
            " 3   date     23481 non-null  object\n",
            "dtypes: object(4)\n",
            "memory usage: 733.9+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df_true 정보 확인\n",
        "df_true.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfMk3Pw0xH9B",
        "outputId": "129fb48e-3eca-4afe-a549-b5893f321f9b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 21417 entries, 0 to 21416\n",
            "Data columns (total 4 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   title    21417 non-null  object\n",
            " 1   text     21417 non-null  object\n",
            " 2   subject  21417 non-null  object\n",
            " 3   date     21417 non-null  object\n",
            "dtypes: object(4)\n",
            "memory usage: 669.4+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# label 생성\n",
        "df_fake['label'] = 1\n",
        "df_true['label'] = 0\n",
        "\n",
        "# 두 데이터프레임 연결\n",
        "df = pd.concat([df_fake, df_true], ignore_index = True)\n",
        "\n",
        "# 데이터프레임 셔플\n",
        "df = df.sample(frac = 1).reset_index(drop = True)\n",
        "\n",
        "# 사용할 데이터프레임 정보 확인\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-aVmto8wHcC",
        "outputId": "6851700d-f906-4527-be19-edbc07fdc826"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 44898 entries, 0 to 44897\n",
            "Data columns (total 5 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   title    44898 non-null  object\n",
            " 1   text     44898 non-null  object\n",
            " 2   subject  44898 non-null  object\n",
            " 3   date     44898 non-null  object\n",
            " 4   label    44898 non-null  int64 \n",
            "dtypes: int64(1), object(4)\n",
            "memory usage: 1.7+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터프레임 내용을 직접 확인\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Z6W34RnN1E83",
        "outputId": "d3534cfc-43d3-4b59-ea52-c39ba2ca3877"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               title  \\\n",
              "0  Ben Stein Calls Out 9th Circuit Court: Committ...   \n",
              "1  Trump drops Steve Bannon from National Securit...   \n",
              "2  Puerto Rico expects U.S. to lift Jones Act shi...   \n",
              "3   OOPS: Trump Just Accidentally Confirmed He Le...   \n",
              "4  Donald Trump heads for Scotland to reopen a go...   \n",
              "\n",
              "                                                text       subject  \\\n",
              "0  21st Century Wire says Ben Stein, reputable pr...       US_News   \n",
              "1  WASHINGTON (Reuters) - U.S. President Donald T...  politicsNews   \n",
              "2  (Reuters) - Puerto Rico Governor Ricardo Rosse...  politicsNews   \n",
              "3  On Monday, Donald Trump once again embarrassed...          News   \n",
              "4  GLASGOW, Scotland (Reuters) - Most U.S. presid...  politicsNews   \n",
              "\n",
              "                  date  label  \n",
              "0    February 13, 2017      1  \n",
              "1       April 5, 2017       0  \n",
              "2  September 27, 2017       0  \n",
              "3         May 22, 2017      1  \n",
              "4       June 24, 2016       0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b40db73f-47ff-43e7-a7b8-1be7ddeb5c88\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>subject</th>\n",
              "      <th>date</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ben Stein Calls Out 9th Circuit Court: Committ...</td>\n",
              "      <td>21st Century Wire says Ben Stein, reputable pr...</td>\n",
              "      <td>US_News</td>\n",
              "      <td>February 13, 2017</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Trump drops Steve Bannon from National Securit...</td>\n",
              "      <td>WASHINGTON (Reuters) - U.S. President Donald T...</td>\n",
              "      <td>politicsNews</td>\n",
              "      <td>April 5, 2017</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Puerto Rico expects U.S. to lift Jones Act shi...</td>\n",
              "      <td>(Reuters) - Puerto Rico Governor Ricardo Rosse...</td>\n",
              "      <td>politicsNews</td>\n",
              "      <td>September 27, 2017</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>OOPS: Trump Just Accidentally Confirmed He Le...</td>\n",
              "      <td>On Monday, Donald Trump once again embarrassed...</td>\n",
              "      <td>News</td>\n",
              "      <td>May 22, 2017</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Donald Trump heads for Scotland to reopen a go...</td>\n",
              "      <td>GLASGOW, Scotland (Reuters) - Most U.S. presid...</td>\n",
              "      <td>politicsNews</td>\n",
              "      <td>June 24, 2016</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b40db73f-47ff-43e7-a7b8-1be7ddeb5c88')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b40db73f-47ff-43e7-a7b8-1be7ddeb5c88 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b40db73f-47ff-43e7-a7b8-1be7ddeb5c88');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbxEHBanUo9d"
      },
      "source": [
        "## 2.1 TF-IDF 를 활용하여 특정 뉴스와 유사한 뉴스 검색하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4R5mLMS5c2I"
      },
      "source": [
        "시간상 특별한 **전처리 없이** 아래 태스크를 수행하겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2B-6Wkk5YGD"
      },
      "source": [
        "### 2.1.1 TFidfVectorizer를 사용하여 문서-단어 행렬(Document-Term Matrix) 만들기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "0Kw9OQwmUo9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "outputId": "d1d1a55d-836b-49a5-fd24-f380825a8f37"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       000      2016  according  administration   america  american  \\\n",
              "0      0.0  0.000000   0.000000        0.000000  0.000000  0.000000   \n",
              "1      0.0  0.000000   0.000000        0.183190  0.044892  0.000000   \n",
              "2      0.0  0.000000   0.000000        0.347947  0.000000  0.160179   \n",
              "3      0.0  0.000000   0.152444        0.000000  0.000000  0.000000   \n",
              "4      0.0  0.000000   0.000000        0.000000  0.000000  0.000000   \n",
              "...    ...       ...        ...             ...       ...       ...   \n",
              "44893  0.0  0.000000   0.000000        0.000000  0.000000  0.000000   \n",
              "44894  0.0  0.097009   0.000000        0.000000  0.000000  0.000000   \n",
              "44895  0.0  0.000000   0.000000        0.000000  0.000000  0.000000   \n",
              "44896  0.0  0.000000   0.091836        0.000000  0.000000  0.000000   \n",
              "44897  0.0  0.000000   0.092832        0.000000  0.099478  0.000000   \n",
              "\n",
              "       americans     asked    called  campaign  ...  washington       way  \\\n",
              "0       0.000000  0.000000  0.000000  0.000000  ...    0.188896  0.000000   \n",
              "1       0.000000  0.000000  0.041490  0.041127  ...    0.075784  0.042245   \n",
              "2       0.000000  0.177877  0.000000  0.000000  ...    0.000000  0.000000   \n",
              "3       0.000000  0.000000  0.000000  0.000000  ...    0.000000  0.000000   \n",
              "4       0.178402  0.000000  0.074386  0.294941  ...    0.000000  0.000000   \n",
              "...          ...       ...       ...       ...  ...         ...       ...   \n",
              "44893   0.000000  0.000000  0.000000  0.000000  ...    0.000000  0.000000   \n",
              "44894   0.000000  0.000000  0.000000  0.000000  ...    0.000000  0.084908   \n",
              "44895   0.000000  0.000000  0.000000  0.000000  ...    0.000000  0.000000   \n",
              "44896   0.218133  0.000000  0.000000  0.000000  ...    0.000000  0.000000   \n",
              "44897   0.000000  0.000000  0.000000  0.000000  ...    0.000000  0.000000   \n",
              "\n",
              "       wednesday      week     white  women      work     world      year  \\\n",
              "0       0.000000  0.000000  0.000000    0.0  0.234041  0.000000  0.000000   \n",
              "1       0.046241  0.000000  0.240405    0.0  0.000000  0.045513  0.035526   \n",
              "2       0.175657  0.000000  0.000000    0.0  0.000000  0.000000  0.000000   \n",
              "3       0.000000  0.000000  0.000000    0.0  0.000000  0.000000  0.000000   \n",
              "4       0.000000  0.074934  0.071836    0.0  0.000000  0.000000  0.000000   \n",
              "...          ...       ...       ...    ...       ...       ...       ...   \n",
              "44893   0.000000  0.000000  0.000000    0.0  0.000000  0.000000  0.000000   \n",
              "44894   0.092938  0.000000  0.000000    0.0  0.000000  0.000000  0.071404   \n",
              "44895   0.000000  0.000000  0.000000    0.0  0.700265  0.000000  0.000000   \n",
              "44896   0.101366  0.000000  0.175668    0.0  0.000000  0.000000  0.000000   \n",
              "44897   0.000000  0.000000  0.000000    0.0  0.000000  0.000000  0.000000   \n",
              "\n",
              "       years  \n",
              "0        0.0  \n",
              "1        0.0  \n",
              "2        0.0  \n",
              "3        0.0  \n",
              "4        0.0  \n",
              "...      ...  \n",
              "44893    0.0  \n",
              "44894    0.0  \n",
              "44895    0.0  \n",
              "44896    0.0  \n",
              "44897    0.0  \n",
              "\n",
              "[44898 rows x 100 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ab377089-6090-43b9-8c1c-31b54fdc3201\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>000</th>\n",
              "      <th>2016</th>\n",
              "      <th>according</th>\n",
              "      <th>administration</th>\n",
              "      <th>america</th>\n",
              "      <th>american</th>\n",
              "      <th>americans</th>\n",
              "      <th>asked</th>\n",
              "      <th>called</th>\n",
              "      <th>campaign</th>\n",
              "      <th>...</th>\n",
              "      <th>washington</th>\n",
              "      <th>way</th>\n",
              "      <th>wednesday</th>\n",
              "      <th>week</th>\n",
              "      <th>white</th>\n",
              "      <th>women</th>\n",
              "      <th>work</th>\n",
              "      <th>world</th>\n",
              "      <th>year</th>\n",
              "      <th>years</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.188896</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.234041</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.183190</td>\n",
              "      <td>0.044892</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.041490</td>\n",
              "      <td>0.041127</td>\n",
              "      <td>...</td>\n",
              "      <td>0.075784</td>\n",
              "      <td>0.042245</td>\n",
              "      <td>0.046241</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.240405</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.045513</td>\n",
              "      <td>0.035526</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.347947</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.160179</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.177877</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.175657</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.152444</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.178402</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.074386</td>\n",
              "      <td>0.294941</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.074934</td>\n",
              "      <td>0.071836</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44893</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44894</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.097009</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.084908</td>\n",
              "      <td>0.092938</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.071404</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44895</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.700265</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44896</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.091836</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.218133</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.101366</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.175668</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44897</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.092832</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.099478</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>44898 rows × 100 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ab377089-6090-43b9-8c1c-31b54fdc3201')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ab377089-6090-43b9-8c1c-31b54fdc3201 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ab377089-6090-43b9-8c1c-31b54fdc3201');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# TfidfVectorizer 생성\n",
        "tfidf_vect = TfidfVectorizer(stop_words = 'english', max_features = 100)\n",
        "\n",
        "# dtm 생성\n",
        "dtm_tfidf_news = tfidf_vect.fit_transform(df['text'])\n",
        "\n",
        "dtm_tfidf_news = pd.DataFrame(dtm_tfidf_news.todense(), columns = tfidf_vect.get_feature_names_out())\n",
        "dtm_tfidf_news"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeTMNUMM5WgQ"
      },
      "source": [
        "### 2.1.2 KNN 알고리즘을 사용하여 유사한 문서 검색하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sP5F90GMpCZJ"
      },
      "source": [
        "- **42번 인덱스의 문서**와 가장 유사한 **5개 문서(42번 포함)의 인덱스**와 **해당 인덱스의 레이블**을 나타내주세요.\n",
        "- NN 모델의 파라미터 중 `algorithm = 'kd_tree'` 로 설정합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "8jjaQO8O6UKd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f28632f8-3411-40ae-b393-90882c23bd06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0.        , 0.        , 0.79745612, 0.83997222, 0.87030389]]),\n",
              " array([[33954,    42, 36664, 31854,  5235]]))"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# NN 모델 생성\n",
        "nn = NearestNeighbors(n_neighbors = 5, algorithm = 'kd_tree')\n",
        "nn.fit(dtm_tfidf_news)\n",
        "\n",
        "# 유사한 문서 검색\n",
        "nn.kneighbors([dtm_tfidf_news.iloc[42]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghQSPbQE7P8b"
      },
      "source": [
        "## 2.2 Keras Embedding을 사용하여 분류하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEl8iU6j8I4M"
      },
      "source": [
        "### 2.2.0 데이터셋 split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eU0Ao8V-pCZL"
      },
      "source": [
        "- Train, Test 데이터셋으로 분리(Split)하여 주세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "55XSZyY_Sj54"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 데이터 분리\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.2, random_state = 42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1xXxSMn7fyt"
      },
      "source": [
        "### 2.2.1 단어 벡터의 평균을 이용하여 분류해보기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_ZsjAVg7ndG"
      },
      "source": [
        "N422에서 했던 단어 임베딩 벡터의 평균을 사용하여 문장을 분류하는 작업을 수행해봅시다.<br/>\n",
        "인스턴스마다 텍스트 길이가 길고 시간이 오래 걸리므로 시간상 epoch 수를 **10 이하**로 하는 것을 추천드립니다.<br/>\n",
        "모델 구동이 목적이므로 임베딩 차원 수를 크지 않게(50이하)로 설정해주세요.<br/>\n",
        "**권장사항 : `max_len` 은 텍스트 길이 평균보다 높게 설정해주세요.**<br/>\n",
        "\n",
        "> **Tip : 모델이 학습하는 동안 2.2.3의 내용을 작성하면 시간을 절약할 수 있습니다.**\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpRlQLXx_4J1",
        "outputId": "41f7ff5d-096c-4d61-9697-8fa91ae3f987"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Collecting gensim\n",
            "  Downloading gensim-4.2.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.1 MB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.21.6)\n",
            "Installing collected packages: gensim\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed gensim-4.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "import gensim.downloader as api\n",
        "\n",
        "print(gensim.__version__)\n",
        "wv = api.load('word2vec-google-news-300')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYmfspsr_8v2",
        "outputId": "3bf2d262-bdeb-4e51-c626-0b99d58032e5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.2.0\n",
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# max_len 길이 확인\n",
        "print(f'텍스트 길이의 평균: {np.mean([len(sent) for sent in X_train], dtype=int)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rIg6oJ_-73y",
        "outputId": "4996cf08-e238-4b6c-9d00-6d24671f388e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "텍스트 길이의 평균: 2465\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "dHber3qBBwOl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f65155a1-9524-413f-b564-329912df22e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합의 크기 : 125516\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# keras의 tokenizer에 텍스트를 학습\n",
        "tokenizer = Tokenizer(num_words = 1000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "# 텍스트 인코딩 진행\n",
        "X_train_encoded = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_encoded = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "# 단어 집합의 크기를 확인\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print('단어 집합의 크기 :', vocab_size)\n",
        "\n",
        "# 패딩 처리\n",
        "max_len = 2500\n",
        "X_train = pad_sequences(X_train_encoded, maxlen = max_len, padding='post')\n",
        "X_test = pad_sequences(X_test_encoded, maxlen = max_len, padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# word2vec의 임베딩 가중치 행렬 생성\n",
        "embedding_matrix = np.zeros((vocab_size, 300))\n",
        "print(np.shape(embedding_matrix))\n",
        "\n",
        "# 입력 단어가 vocab에 있는 단어일 경우 임베딩 벡터를 반환하는 함수 작성\n",
        "def get_vector(word):\n",
        "    if word in wv:\n",
        "        return wv[word]\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# 함수를 적용하여 embedding_matrix 생성\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    temp = get_vector(word)\n",
        "    if temp is not None:\n",
        "        embedding_matrix[i] = temp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOa6Kjhz_tV1",
        "outputId": "2916ffe5-80aa-4237-a016-639aedc5fb71"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(125516, 300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
        "\n",
        "# 신경망 구성\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 300, weights = [embedding_matrix], input_length = max_len, trainable = False))\n",
        "model.add(GlobalAveragePooling1D())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# 모델 학습\n",
        "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['acc'])\n",
        "model.fit(X_train, y_train, batch_size = 64, epochs = 3, validation_split = 0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkZEkNmHA6-L",
        "outputId": "c223d5a9-4819-448c-e876-b52262440c74"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "449/449 [==============================] - 4s 7ms/step - loss: 0.6830 - acc: 0.5266 - val_loss: 0.6760 - val_acc: 0.5146\n",
            "Epoch 2/3\n",
            "449/449 [==============================] - 3s 7ms/step - loss: 0.6673 - acc: 0.5758 - val_loss: 0.6615 - val_acc: 0.6719\n",
            "Epoch 3/3\n",
            "449/449 [==============================] - 3s 6ms/step - loss: 0.6534 - acc: 0.7056 - val_loss: 0.6483 - val_acc: 0.7215\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fed25cbb510>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 평가 진행\n",
        "eval = model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DMWql9MBfBS",
        "outputId": "3c275acf-dfa8-449a-d925-8215da94e065"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "281/281 [==============================] - 1s 3ms/step - loss: 0.6474 - acc: 0.7229\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SzUwLkcAK1A"
      },
      "source": [
        "### 2.2.2 LSTM을 사용하여 텍스트 분류 수행해보기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4UZ9ZqOAIjw"
      },
      "source": [
        "N423에서 했던 단어 임베딩 벡터의 평균을 사용하여 문장을 분류하는 작업을 수행해봅시다.<br/>\n",
        "인스턴스마다 텍스트 길이가 길어 시간이 매우 오래 걸리므로 <br/>\n",
        "**층을 최소한으로 쌓고**, epoch 수를 **3 이하**로 하는 것을 추천드립니다.<br/>\n",
        "\n",
        "> **Tip : 모델이 학습하는 동안 2.2.3의 내용을 작성하면 시간을 절약할 수 있습니다.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "9PLNlzEVBSyE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecbbbb77-56d9-44e5-d798-2a5bca061d65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " inputs (InputLayer)         [(None, 2500)]            0         \n",
            "                                                                 \n",
            " embedding_13 (Embedding)    (None, 2500, 50)          6275800   \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 64)                29440     \n",
            "                                                                 \n",
            " FC1 (Dense)                 (None, 256)               16640     \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " out_layer (Dense)           (None, 1)                 257       \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,322,137\n",
            "Trainable params: 6,322,137\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras.layers import LSTM, Activation, Dropout, Input\n",
        "from keras.models import Model\n",
        "from keras.optimizers import RMSprop\n",
        "\n",
        "# 모델 생성\n",
        "def RNN():\n",
        "    inputs = Input(name = 'inputs',shape = [max_len])\n",
        "    layer = Embedding(vocab_size, 50, input_length = max_len)(inputs)\n",
        "    layer = LSTM(64)(layer)\n",
        "    layer = Dense(256, name = 'FC1')(layer)\n",
        "    layer = Activation('relu')(layer)\n",
        "    layer = Dropout(0.5)(layer)\n",
        "    layer = Dense(1, name = 'out_layer')(layer)\n",
        "    layer = Activation('sigmoid')(layer)\n",
        "    model = Model(inputs=inputs,outputs=layer)\n",
        "    return model\n",
        "\n",
        "model = RNN()\n",
        "model.summary()\n",
        "model.compile(loss = 'binary_crossentropy', optimizer = RMSprop(), metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 학습\n",
        "model.fit(X_train, y_train, batch_size = 64, epochs = 3, validation_split = 0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCWseqqwFniR",
        "outputId": "11d3b3bd-9fcc-4bf7-fab4-dc8186eb3622"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "449/449 [==============================] - 44s 93ms/step - loss: 0.6924 - accuracy: 0.5220 - val_loss: 0.6942 - val_accuracy: 0.5146\n",
            "Epoch 2/3\n",
            "449/449 [==============================] - 42s 93ms/step - loss: 0.7006 - accuracy: 0.5234 - val_loss: 0.6931 - val_accuracy: 0.5146\n",
            "Epoch 3/3\n",
            "449/449 [==============================] - 39s 87ms/step - loss: 0.6997 - accuracy: 0.5243 - val_loss: 0.6929 - val_accuracy: 0.5146\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fed27abf6d0>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 평가\n",
        "eval = model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRElav_rF533",
        "outputId": "a2a52949-4617-4111-f037-d266697bbeaa"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "281/281 [==============================] - 9s 30ms/step - loss: 0.6914 - accuracy: 0.5245\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsNOs2wmBV1z"
      },
      "source": [
        "### 2.2.3 위에서 실행한 내용에 대해 다시 알아봅시다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMR2t2wOEPYm"
      },
      "source": [
        "#### a) 데이터셋을 학습할 때 사용하는 `pad_sequences`  메서드에 대해 설명해주세요.<br/>어떤 기능을 하나요? 모델을 학습할 때 왜 필요한가요?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7_ECWSYQ4JV"
      },
      "source": [
        "*자연어 처리를 하다보면 각 문장의 길이가 서로 다를 수 있는데, 기계는 길이가 전부 동일한 문서들에 대해 하나의 행렬로 보고 한꺼번에 처리가 가능하다. 따라서, pad_sequences를 통해 여러 문장의 길이를 임의로 동일하게 맞춰주는 작업을 함으로써, 병렬 연산이 가능하게 한다.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeZ6AcloEYD5"
      },
      "source": [
        "#### b) 2.2.1과 2.2.2에서 사용한 각 모델의 evaluation 성능은 어떻게 나왔나요?<br/>각 모델의 장단점은 무엇이라고 생각하나요?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SyqQzzHQ4EP"
      },
      "source": [
        "*2.2.1의 모델* \n",
        "1. embedding_matrix를 사용한 경우 정확도 : 0.7229\n",
        "2. embedding_matrix를 사용하지 않은 경우 정확도 : 0.5246\n",
        "3. 장점<br>\n",
        "    - 구현이 간편\n",
        "    - 간단한 문제에 대해서는 성능이 좋음\n",
        "4. 단점\n",
        "    - 문장에서의 단어 위치정보를 이용할 수 없음\n",
        "\n",
        "*2.2.2의 모델* \n",
        "1. 정확도 : 0.5245\n",
        "2. 장점\n",
        "    - 각각의 메모리와 결과값이 컨트롤이 가능\n",
        "3. 단점\n",
        "    - 메모리가 덮어씌워질 가능성이 있음\n",
        "    - 연산 속도가 느림\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUwKojAGM82f"
      },
      "source": [
        "#### c) 종래의 RNN(Recurrent Neural Networks) 대신 LSTM(Long-Short Term Memory)을 사용하는 이유는 무엇인가요?<br/>(i.e. RNN에 비해 LSTM의 좋은 점을 설명해주세요.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6y44XfugQ_HR"
      },
      "source": [
        "*기존의 RNN은 단기 메모리만을 가지고 학습을 진행해서 장기 의존성의 문제가 존재했다. 하지만 LSTM은 단기 메모리와 장기 메모리를 나눠 학습 후, 두 메모리를 병합해 이벤트 확률을 예측하기 때문에 과거의 정보를 훨씬 잘 반영한다는 장점이 있다.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0J1kzTmDEaLU"
      },
      "source": [
        "#### d) LSTM이나 RNN을 사용하는 예시를 **3개**이상 제시하고 해당되는 경우에 왜 LSTM이나 RNN을 사용하는 것 적절한지 간단하게 설명해주세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ck8GPjc_Q_vA"
      },
      "source": [
        "사용 예시 : 챗봇, 기계 번역, 음성 인식 등 <br>\n",
        "사용 이유 : LSTM이나 RNN이 속하는 Sequence Model이란, 연속적인 입력으로부터 연속적인 출력을 생성하는 모델로서 순서가 있는 Sequence data에서 특징들을 추출하여 여러가지 문제를 해결하고 예측하기 때문에"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4pP7g8DE0Cz"
      },
      "source": [
        "#### e) 이외에 N424 에서 배운 자연어처리 모델과 관련된 키워드를 3개 이상 적어주세요. <br/> (해당 키워드에 대한 설명은 옵션입니다.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-sO4mMuRAhp"
      },
      "source": [
        "*GPT 모델, BERT 모델, T5 모델*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRn44qjhUo9j"
      },
      "source": [
        "# Advanced Goals: 3점을 획득하기 위해선 아래의 조건 중 하나 이상을 만족해야합니다\n",
        " \n",
        "- 2.1 에서 TF-IDF(`TfidfVectorizer`)가 아닌 방법을 사용하여 유사도 검색을 수행해보세요.<br/>\n",
        "TF-IDF와 해당 방법의 차이를 설명해주세요. \n",
        "- 2.2 에서 사용한 방법을 재사용하되 하이퍼 파라미터를 조정하거나 모델 구조를 변경하여 성능을 올려봅시다.<br/>**(주의 : GridSearch, RandomSearch 등의 방법을 사용하여도 좋으나 시간이 오래 걸리므로 범위를 잘 선택해야 합니다.)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lz2uaXFYUo9j"
      },
      "outputs": [],
      "source": [
        "# 이 곳에 답안을 작성하시길 바랍니다"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernel_info": {
      "name": "u4-s1-nlp"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    },
    "nteract": {
      "version": "0.22.4"
    },
    "toc-autonumbering": false,
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}